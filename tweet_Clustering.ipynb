{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "I4BNvXNQylAL"
      },
      "outputs": [],
      "source": [
        "#output from workflow Clustering hashtags\n",
        "representative_hashtags=['ichbinhanna', 'waspostdocswollen', 'hochschulen', 'wisskomm', 'dauerstellen', 'hannaimbundestag', 'academictwitter', 'berlhg', 'wissenschaft', 'tvstud', 'bmbf', '27juni', 'twittercampus', 'dasgewinnenwir', 'ugnovelle', 'karliczek', 'corona']\n",
        "def tweet_clustering(dataset,tweet_id,rep_hashtags):\n",
        "  model = SentenceTransformer('T-Systems-onsite/cross-en-de-roberta-sentence-transformer')\n",
        "  hashclusters=set()\n",
        "  tweet_hashtags=list()\n",
        "  embedding_full = model.encode(rep_hashtags)\n",
        "  hashtags=str(list(df[df.tweet_id==tweet_id].hashtags))\n",
        "  hashtags=hashtags.split(', ')\n",
        "  a=[re.search(r\"[\\[\\'\\\"]*(\\w*)[\\]\\']*\",i).group(1) for i in hashtags]\n",
        "  tweet_hashtags.extend(a)\n",
        "  #print(a)\n",
        "  if not tweet_hashtags[0]:\n",
        "    print(\"no hashtags found for this tweet\")\n",
        "    return \n",
        "\n",
        "  for tw_hash in tweet_hashtags:\n",
        "    embedding = model.encode(tw_hash)\n",
        "    for rep_hash in rep_hashtags:\n",
        "        if util.pytorch_cos_sim(embedding,model.encode(rep_hash)) > 0.5:\n",
        "            hashclusters.add(rep_hash)\n",
        "\n",
        "  return  hashclusters  "
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jaZrP9gozHTy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}